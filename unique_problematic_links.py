#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import os
from datetime import datetime

def get_unique_problematic_links():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Å—ã–ª–æ–∫ –Ω–∞ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å—Ç–∞—Ç—å–∏"""
    
    # –ò—â–µ–º —Ñ–∞–π–ª –æ—Ç—á–µ—Ç–∞ –∞—É–¥–∏—Ç–∞
    report_files = [f for f in os.listdir('.') if f.startswith('audit_featured_images_report_') and f.endswith('.json')]
    
    if not report_files:
        print("‚ùå –§–∞–π–ª –æ—Ç—á–µ—Ç–∞ –∞—É–¥–∏—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    latest_report = sorted(report_files)[-1]
    
    with open(latest_report, 'r', encoding='utf-8') as f:
        report_data = json.load(f)
    
    detailed_results = report_data.get('detailed_results', [])
    problematic_articles = [article for article in detailed_results if not article['is_match']]
    
    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
    unique_articles = {}
    
    for article in problematic_articles:
        post_id = article['post_id']
        if post_id not in unique_articles:
            unique_articles[post_id] = article
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º –ø—Ä–æ–±–ª–µ–º
    placeholder_issues = []
    wrong_images = []
    missing_images = []
    
    for article in unique_articles.values():
        reason = article['reason'].lower()
        if 'placeholder' in reason:
            placeholder_issues.append(article)
        elif '—Ä–∞–∑–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è' in reason:
            wrong_images.append(article)
        elif '–Ω–µ –Ω–∞–π–¥–µ–Ω–æ' in reason:
            missing_images.append(article)
    
    print("üîó –£–ù–ò–ö–ê–õ–¨–ù–´–ï –°–°–´–õ–ö–ò –ù–ê –ü–†–û–ë–õ–ï–ú–ù–´–ï –°–¢–ê–¢–¨–ò")
    print("=" * 60)
    print(f"üìä –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π: {len(unique_articles)}")
    print()
    
    # 1. Placeholder –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï)
    print("üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï - PLACEHOLDER –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø:")
    print("-" * 50)
    for article in sorted(placeholder_issues, key=lambda x: x['post_id']):
        post_id = article['post_id']
        title = article['title']
        url = f"https://ecopackpro.ru/?p={post_id}&preview=true"
        print(f"ID {post_id}: {title}")
        print(f"üîó {url}")
        print()
    
    # 2. –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    print("‚ö†Ô∏è  –ù–ï–ü–†–ê–í–ò–õ–¨–ù–´–ï –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø:")
    print("-" * 50)
    for article in sorted(wrong_images, key=lambda x: x['post_id']):
        post_id = article['post_id']
        title = article['title']
        url = f"https://ecopackpro.ru/?p={post_id}&preview=true"
        print(f"ID {post_id}: {title}")
        print(f"üîó {url}")
        print()
    
    # 3. –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    if missing_images:
        print("üì≠ –û–¢–°–£–¢–°–¢–í–£–Æ–©–ò–ï –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø:")
        print("-" * 50)
        for article in sorted(missing_images, key=lambda x: x['post_id']):
            post_id = article['post_id']
            title = article['title']
            url = f"https://ecopackpro.ru/?p={post_id}&preview=true"
            print(f"ID {post_id}: {title}")
            print(f"üîó {url}")
            print()
    
    print("üìã –ò–¢–û–ì–û:")
    print(f"üî• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö (placeholder): {len(placeholder_issues)}")
    print(f"‚ö†Ô∏è  –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(wrong_images)}")
    print(f"üì≠ –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö: {len(missing_images)}")
    print(f"üéØ –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {len(unique_articles)}")

if __name__ == "__main__":
    get_unique_problematic_links()
