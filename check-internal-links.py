#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
üîç –ü–†–û–í–ï–†–ö–ê –í–ù–£–¢–†–ï–ù–ù–ò–• –°–°–´–õ–û–ö –ù–ê –ö–û–î –û–¢–í–ï–¢–ê 200
–°–∞–π—Ç: ecopackpro.ru
–¶–µ–ª—å: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –≤—Å–µ—Ö —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å—Å—ã–ª–æ–∫
"""

import mysql.connector
import requests
import time
from datetime import datetime
import logging
from urllib.parse import urlparse
import concurrent.futures
from threading import Lock

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/var/www/fastuser/data/www/ecopackpro.ru/links_check.log'),
        logging.StreamHandler()
    ]
)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
DB_CONFIG = {
    'host': 'localhost',
    'user': 'm1shqamai2_worp6',
    'password': '9nUQkM*Q2cnvy379',
    'database': 'm1shqamai2_worp6'
}

class InternalLinksChecker:
    def __init__(self):
        self.db_config = DB_CONFIG
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏
        self.stats = {
            'total_links': 0,
            'working_links': 0,
            'broken_links': 0,
            'redirects': 0,
            'timeouts': 0,
            'errors': 0
        }
        
        self.lock = Lock()
        self.results = []
    
    def connect_to_database(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            connection = mysql.connector.connect(**self.db_config)
            return connection
        except mysql.connector.Error as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
            return None
    
    def extract_internal_links(self):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ—Ö –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å—Å—ã–ª–æ–∫ –∏–∑ —Å—Ç–∞—Ç–µ–π"""
        logging.info("üîç –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å—Å—ã–ª–∫–∏ –∏–∑ —Å—Ç–∞—Ç–µ–π...")
        
        connection = self.connect_to_database()
        if not connection:
            return []
        
        cursor = connection.cursor()
        
        # –ò—â–µ–º –≤—Å–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å—Å—ã–ª–∫–∏ –≤ –∫–æ–Ω—Ç–µ–Ω—Ç–µ —Å—Ç–∞—Ç–µ–π
        cursor.execute("""
            SELECT ID, post_title, post_content 
            FROM wp_posts 
            WHERE post_status = 'publish' 
            AND post_type = 'post'
            AND post_content LIKE '%href="https://ecopackpro.ru/%'
        """)
        
        articles = cursor.fetchall()
        internal_links = []
        
        import re
        
        for article_id, title, content in articles:
            # –ò—â–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ ecopackpro.ru
            link_pattern = r'href="(https://ecopackpro\.ru/[^"]+)"'
            links = re.findall(link_pattern, content)
            
            for link in links:
                internal_links.append({
                    'url': link,
                    'source_article_id': article_id,
                    'source_title': title
                })
        
        connection.close()
        
        self.stats['total_links'] = len(internal_links)
        logging.info(f"üìä –ù–∞–π–¥–µ–Ω–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å—Å—ã–ª–æ–∫: {len(internal_links)}")
        
        return internal_links
    
    def check_single_link(self, link_info):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–¥–Ω–æ–π —Å—Å—ã–ª–∫–∏"""
        url = link_info['url']
        source_title = link_info['source_title']
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Å—ã–ª–∫—É —Å —Ç–∞–π–º–∞—É—Ç–æ–º
            response = self.session.get(url, timeout=10, allow_redirects=True)
            
            result = {
                'url': url,
                'status_code': response.status_code,
                'source_title': source_title,
                'final_url': response.url,
                'redirect_count': len(response.history),
                'response_time': response.elapsed.total_seconds(),
                'error': None
            }
            
            with self.lock:
                if response.status_code == 200:
                    self.stats['working_links'] += 1
                    logging.info(f"‚úÖ {url} - {response.status_code} ({result['response_time']:.2f}s)")
                elif 300 <= response.status_code < 400:
                    self.stats['redirects'] += 1
                    logging.warning(f"üîÑ {url} - {response.status_code} (—Ä–µ–¥–∏—Ä–µ–∫—Ç –Ω–∞ {response.url})")
                else:
                    self.stats['broken_links'] += 1
                    logging.error(f"‚ùå {url} - {response.status_code}")
            
            return result
            
        except requests.exceptions.Timeout:
            with self.lock:
                self.stats['timeouts'] += 1
            logging.error(f"‚è∞ {url} - Timeout")
            return {
                'url': url,
                'status_code': 'Timeout',
                'source_title': source_title,
                'error': 'Timeout'
            }
            
        except requests.exceptions.RequestException as e:
            with self.lock:
                self.stats['errors'] += 1
            logging.error(f"üí• {url} - Error: {str(e)}")
            return {
                'url': url,
                'status_code': 'Error',
                'source_title': source_title,
                'error': str(e)
            }
    
    def check_links_concurrent(self, links, max_workers=10):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Å—ã–ª–æ–∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ"""
        logging.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É {len(links)} —Å—Å—ã–ª–æ–∫ (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ, {max_workers} –ø–æ—Ç–æ–∫–æ–≤)...")
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏
            future_to_link = {
                executor.submit(self.check_single_link, link): link 
                for link in links
            }
            
            # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for future in concurrent.futures.as_completed(future_to_link):
                try:
                    result = future.result()
                    self.results.append(result)
                except Exception as e:
                    logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Å—ã–ª–∫–∏: {e}")
    
    def generate_links_report(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Å—ã–ª–æ–∫"""
        logging.info("üìã –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Å—ã–ª–æ–∫...")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        working_links = [r for r in self.results if r['status_code'] == 200]
        broken_links = [r for r in self.results if r['status_code'] != 200 and r['status_code'] != 'Timeout' and r['status_code'] != 'Error']
        redirect_links = [r for r in self.results if isinstance(r['status_code'], int) and 300 <= r['status_code'] < 400]
        error_links = [r for r in self.results if r['status_code'] in ['Timeout', 'Error']]
        
        report = f"""
# üîç –û–¢–ß–ï–¢ –û –ü–†–û–í–ï–†–ö–ï –í–ù–£–¢–†–ï–ù–ù–ò–• –°–°–´–õ–û–ö
**–°–∞–π—Ç:** ecopackpro.ru  
**–î–∞—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## üìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê

- **–í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ —Å—Å—ã–ª–æ–∫:** {self.stats['total_links']}
- **‚úÖ –†–∞–±–æ—Ç–∞—é—â–∏—Ö —Å—Å—ã–ª–æ–∫ (200):** {self.stats['working_links']} ({self.stats['working_links']/self.stats['total_links']*100:.1f}%)
- **‚ùå –ù–µ—Ä–∞–±–æ—Ç–∞—é—â–∏—Ö —Å—Å—ã–ª–æ–∫:** {self.stats['broken_links']} ({self.stats['broken_links']/self.stats['total_links']*100:.1f}%)
- **üîÑ –†–µ–¥–∏—Ä–µ–∫—Ç–æ–≤:** {self.stats['redirects']} ({self.stats['redirects']/self.stats['total_links']*100:.1f}%)
- **‚è∞ –¢–∞–π–º–∞—É—Ç–æ–≤:** {self.stats['timeouts']}
- **üí• –û—à–∏–±–æ–∫:** {self.stats['errors']}

## ‚úÖ –†–ê–ë–û–¢–ê–Æ–©–ò–ï –°–°–´–õ–ö–ò ({len(working_links)})

"""
        
        for link in working_links[:20]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 20
            report += f"- ‚úÖ [{link['url']}]({link['url']}) - {link['response_time']:.2f}s\n"
        
        if len(working_links) > 20:
            report += f"... –∏ –µ—â–µ {len(working_links) - 20} —Ä–∞–±–æ—Ç–∞—é—â–∏—Ö —Å—Å—ã–ª–æ–∫\n"
        
        report += f"""
## ‚ùå –ù–ï–†–ê–ë–û–¢–ê–Æ–©–ò–ï –°–°–´–õ–ö–ò ({len(broken_links)})

"""
        
        for link in broken_links:
            report += f"- ‚ùå [{link['url']}]({link['url']}) - –∫–æ–¥ {link['status_code']}\n"
        
        report += f"""
## üîÑ –†–ï–î–ò–†–ï–ö–¢–´ ({len(redirect_links)})

"""
        
        for link in redirect_links:
            report += f"- üîÑ [{link['url']}]({link['url']}) ‚Üí [{link['final_url']}]({link['final_url']}) - –∫–æ–¥ {link['status_code']}\n"
        
        if error_links:
            report += f"""
## üí• –û–®–ò–ë–ö–ò –ò –¢–ê–ô–ú–ê–£–¢–´ ({len(error_links)})

"""
            for link in error_links:
                report += f"- üí• [{link['url']}]({link['url']}) - {link['error']}\n"
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Å—Ç–∞—Ç—å—è–º-–∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
        from collections import defaultdict
        articles_stats = defaultdict(lambda: {'total': 0, 'working': 0, 'broken': 0})
        
        for result in self.results:
            source = result['source_title']
            articles_stats[source]['total'] += 1
            if result['status_code'] == 200:
                articles_stats[source]['working'] += 1
            else:
                articles_stats[source]['broken'] += 1
        
        report += f"""
## üìà –ê–ù–ê–õ–ò–ó –ü–û –°–¢–ê–¢–¨–Ø–ú-–ò–°–¢–û–ß–ù–ò–ö–ê–ú

"""
        
        for article, stats in sorted(articles_stats.items(), key=lambda x: x[1]['total'], reverse=True)[:10]:
            success_rate = stats['working'] / stats['total'] * 100 if stats['total'] > 0 else 0
            report += f"- **{article}:** {stats['working']}/{stats['total']} —Å—Å—ã–ª–æ–∫ ({success_rate:.1f}% —Ä–∞–±–æ—Ç–∞—é—â–∏—Ö)\n"
        
        report += f"""
## üéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò

"""
        
        if self.stats['broken_links'] > 0:
            report += f"1. **–ò—Å–ø—Ä–∞–≤–∏—Ç—å {self.stats['broken_links']} –Ω–µ—Ä–∞–±–æ—Ç–∞—é—â–∏—Ö —Å—Å—ã–ª–æ–∫** - —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è SEO\n"
        
        if self.stats['redirects'] > 0:
            report += f"2. **–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å {self.stats['redirects']} —Ä–µ–¥–∏—Ä–µ–∫—Ç–æ–≤** - –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –ø—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏\n"
        
        if self.stats['timeouts'] > 0:
            report += f"3. **–ü—Ä–æ–≤–µ—Ä–∏—Ç—å {self.stats['timeouts']} —Å—Å—ã–ª–æ–∫ —Å —Ç–∞–π–º–∞—É—Ç–∞–º–∏** - –≤–æ–∑–º–æ–∂–Ω–æ, –ø—Ä–æ–±–ª–µ–º—ã —Å —Å–µ—Ä–≤–µ—Ä–æ–º\n"
        
        success_rate = self.stats['working_links'] / self.stats['total_links'] * 100 if self.stats['total_links'] > 0 else 0
        report += f"4. **–û–±—â–∏–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏: {success_rate:.1f}%** - {'–æ—Ç–ª–∏—á–Ω–æ' if success_rate > 95 else '—Ö–æ—Ä–æ—à–æ' if success_rate > 80 else '—Ç—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è'}\n"
        
        report += f"""
---
*–û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∏—Å—Ç–µ–º–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å—Å—ã–ª–æ–∫*
"""
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        report_filename = f"/var/www/fastuser/data/www/ecopackpro.ru/links_check_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write(report)
        
        logging.info(f"‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_filename}")
        return report_filename
    
    def run_links_check(self):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Å—ã–ª–æ–∫"""
        logging.info("üîç –ó–ê–ü–£–°–ö –ü–†–û–í–ï–†–ö–ò –í–ù–£–¢–†–ï–ù–ù–ò–• –°–°–´–õ–û–ö")
        logging.info("=" * 50)
        
        start_time = datetime.now()
        
        # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å—Å—ã–ª–∫–∏
        links = self.extract_internal_links()
        if not links:
            logging.error("‚ùå –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å—Å—ã–ª–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
            return False
        
        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Å—ã–ª–∫–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        self.check_links_concurrent(links, max_workers=15)
        
        # 3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        report_file = self.generate_links_report()
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        end_time = datetime.now()
        duration = end_time - start_time
        
        logging.info("=" * 50)
        logging.info("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–†–û–í–ï–†–ö–ò")
        logging.info(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration}")
        logging.info(f"üîó –í—Å–µ–≥–æ —Å—Å—ã–ª–æ–∫: {self.stats['total_links']}")
        logging.info(f"‚úÖ –†–∞–±–æ—Ç–∞—é—â–∏—Ö: {self.stats['working_links']} ({self.stats['working_links']/self.stats['total_links']*100:.1f}%)")
        logging.info(f"‚ùå –ù–µ—Ä–∞–±–æ—Ç–∞—é—â–∏—Ö: {self.stats['broken_links']} ({self.stats['broken_links']/self.stats['total_links']*100:.1f}%)")
        logging.info(f"üîÑ –†–µ–¥–∏—Ä–µ–∫—Ç–æ–≤: {self.stats['redirects']}")
        logging.info(f"üìÑ –û—Ç—á–µ—Ç: {report_file}")
        logging.info("=" * 50)
        
        return True

if __name__ == "__main__":
    # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É
    checker = InternalLinksChecker()
    checker.run_links_check()



